{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d7bd0e-be53-4c97-9a6b-2b64a384b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import requests\n",
    "import pandahouse as ph\n",
    "\n",
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import get_current_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68473915-131e-4d10-a42c-cfce3b646052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd3951-ff72-4d67-8d0c-793c6d8ac214",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = {\n",
    "    'host': 'https://clickhouse.lab.karpov.courses',\n",
    "    'password': 'dpo_python_2020',\n",
    "    'user': 'student',\n",
    "    'database': 'simulator'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0094ba-46d7-4ab0-ba31-d179a7f931e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querry(q):\n",
    "    df = pandahouse.read_clickhouse(q, connection=connection)\n",
    "    return df\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "    'owner': 'd.mukasheva',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2022, 3, 10),\n",
    "}\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 23 * * *'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32ce42-06df-4875-bb63-acebcef2bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def dag_sim_dina():\n",
    "\n",
    "    @task()\n",
    "    def feed():\n",
    "        q='''\n",
    "        select\n",
    "        toDate(time) as event_date, \n",
    "        user_id as user,\n",
    "        gender,\n",
    "        age,\n",
    "        os,\n",
    "        countIf(action, action='like') likes,\n",
    "        countIf(action, action='view') views\n",
    "        from simulator_20220320.feed_actions  \n",
    "        where toDate(time)>=yesterday()\n",
    "        group by event_date,user,gender,age,os'''\n",
    "        \n",
    "        df_feed = pandahouse.read_clickhouse(q, connection=connection)\n",
    "        return df_feed\n",
    "        \n",
    "    @task()\n",
    "    def messages(): \n",
    "        q='''\n",
    "        with sent as (\n",
    "        select \n",
    "        toDate(time) as event_date,\n",
    "        user_id as user,\n",
    "        gender,\n",
    "        age,\n",
    "        os,\n",
    "        count(distinct reciever_id) as sent_users,\n",
    "        count(reciever_id) as sent_messages\n",
    "        from simulator_20220320.message_actions\n",
    "        where event_date = yesterday() \n",
    "        group by event_date,user,gender,age,os\n",
    "        ),\n",
    "        received as (\n",
    "        select \n",
    "        toDate(time) as event_date,\n",
    "        reciever_id as user,\n",
    "\n",
    "        count(distinct user_id) as received_users,\n",
    "        count(user_id) as received_messages\n",
    "        from simulator_20220320.message_actions\n",
    "        where event_date = yesterday() \n",
    "        group by event_date,user\n",
    "\n",
    "        )\n",
    "        select \n",
    "        a.event_date,\n",
    "        a.user,\n",
    "        gender,\n",
    "        age,\n",
    "        os,\n",
    "        sent_users,\n",
    "        sent_messages,\n",
    "        received_users,\n",
    "        received_messages\n",
    "        from sent a inner join received b on a.user=b.user '''\n",
    "        \n",
    "        df_messages = pandahouse.read_clickhouse(q, connection=connection)\n",
    "        return df_messages\n",
    "    \n",
    "    @task()\n",
    "    def merge(df_feed, df_messages): \n",
    "        df = pd.merge(df_feed, df_messages, on=['event_date','user','gender','age','os'],how = 'outer')\n",
    "        return df\n",
    "    \n",
    "    @task()\n",
    "    def fintable(df):\n",
    "        df_fin = df[['event_date', 'gender', 'age', 'os', 'views', 'likes', \n",
    "                          'received_messages', 'sent_messages', 'received_users', 'sent_users']]\\\n",
    "            .groupby(['event_date', 'gender', 'age', 'os'], as_index=False)\\\n",
    "            .sum()\n",
    "        df_fin[['likes', 'views', 'sent_messages', 'sent_users', 'received_messages', 'received_users']] = \\\n",
    "        df_fin[['likes', 'views', 'sent_messages', 'sent_users', 'received_messages', 'received_users']].astype(int)\n",
    "        return df_fin\n",
    "    \n",
    "    @task\n",
    "    def load(df_fin):\n",
    "        context = get_current_context()\n",
    "        ds = context['ds']\n",
    "        print(f'Likes per source for {ds}')\n",
    "        print(df_fin.to_csv(index=False, sep='\\t'))\n",
    "        ph.to_clickhouse(df=fin, table='d.mukashev', index=False, \\\n",
    "                         connection = connection1)\n",
    "\n",
    "    df_feed = feed()\n",
    "    df_messages=messages()\n",
    "    df=merge(df_feed, df_messages)\n",
    "    df_fin=fintable(df)\n",
    "\n",
    "dag_sim_dina = dag_sim_dina()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bde377-59fd-4fb3-b4af-f798ddc84a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4ef07-4c69-4526-8c39-fa0a355edf57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafc5f5-0186-4c80-b4bc-405ec5015775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для CH\n",
    "def ch_get_df(query='Select 1', host='https://clickhouse.lab.karpov.courses', user='student', password='dpo_python_2020'):\n",
    "    r = requests.post(host, data=query.encode(\"utf-8\"), auth=(user, password), verify=False)\n",
    "    result = pd.read_csv(StringIO(r.text), sep='\\t')\n",
    "    return result\n",
    "\n",
    "\n",
    "query = \"\"\"SELECT \n",
    "               toDate(time) as event_date, \n",
    "               country, \n",
    "               source,\n",
    "               count() as likes\n",
    "            FROM \n",
    "                simulator.feed_actions \n",
    "            where \n",
    "                toDate(time) = '2022-01-26' \n",
    "                and action = 'like'\n",
    "            group by\n",
    "                event_date,\n",
    "                country,\n",
    "                source\n",
    "            format TSVWithNames\"\"\"\n",
    "\n",
    "# Дефолтные параметры, которые прокидываются в таски\n",
    "default_args = {\n",
    "    'owner': 'a.batalov',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'start_date': datetime(2022, 3, 10),\n",
    "}\n",
    "\n",
    "# Интервал запуска DAG\n",
    "schedule_interval = '0 23 * * *'\n",
    "\n",
    "@dag(default_args=default_args, schedule_interval=schedule_interval, catchup=False)\n",
    "def dag_sim_example():\n",
    "\n",
    "    @task()\n",
    "    def extract():\n",
    "        query = \"\"\"SELECT \n",
    "                       toDate(time) as event_date, \n",
    "                       country, \n",
    "                       source,\n",
    "                       count() as likes\n",
    "                    FROM \n",
    "                        simulator.feed_actions \n",
    "                    where \n",
    "                        toDate(time) = '2022-01-26' \n",
    "                        and action = 'like'\n",
    "                    group by\n",
    "                        event_date,\n",
    "                        country,\n",
    "                        source\n",
    "                    format TSVWithNames\"\"\"\n",
    "        df_cube = ch_get_df(query=query)\n",
    "        return df_cube\n",
    "\n",
    "    @task\n",
    "    def transfrom_source(df_cube):\n",
    "        df_cube_source = df_cube[['event_date', 'source', 'likes']]\\\n",
    "            .groupby(['event_date', 'source'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        return df_cube_source\n",
    "\n",
    "    @task\n",
    "    def transfrom_countries(df_cube):\n",
    "        df_cube_country = df_cube[['event_date', 'country', 'likes']]\\\n",
    "            .groupby(['event_date', 'country'])\\\n",
    "            .sum()\\\n",
    "            .reset_index()\n",
    "        return df_cube_country\n",
    "\n",
    "    @task\n",
    "    def load(df_cube_source, df_cube_country):\n",
    "        context = get_current_context()\n",
    "        ds = context['ds']\n",
    "        print(f'Likes per source for {ds}')\n",
    "        print(df_cube_source.to_csv(index=False, sep='\\t'))\n",
    "        print(f'Likes per country for {ds}')\n",
    "        print(df_cube_country.to_csv(index=False, sep='\\t'))\n",
    "\n",
    "    df_cube = extract()\n",
    "    df_cube_source = transfrom_source(df_cube)\n",
    "    df_cube_country = transfrom_countries(df_cube)\n",
    "    load(df_cube_source, df_cube_country)\n",
    "\n",
    "dag_sim_example = dag_sim_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
